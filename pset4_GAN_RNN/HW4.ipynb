{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 4 - GAN and RNN\n",
    "Designed by Xide Xia, Kubra Cilingir, Vijay Thakkar, Ali Siahkamari, and Brian Kulis, with help from Kun He.\n",
    "\n",
    "This assignment will introduce you to:\n",
    "\n",
    "Part 1 - GAN:\n",
    "1. Implement your GAN on CelebA face data\n",
    "2. Apply your GAN to Image Completion task\n",
    "\n",
    "Part 2 - RNN:\n",
    "1. Implementation of RNN and LSTM\n",
    "2. Training your implemented LSTM\n",
    "3. Composing music using LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Training a GAN model on Celebrity dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs consists of two neural networks, a discriminator and a generator that are pitting against each other. If you do not feel comfortable with how they work, you are encouraged to check the original paper:\n",
    "[Generative adversarial networks paper](https://arxiv.org/pdf/1406.2661.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"gans.png\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given real data coming from $ \\mathbb  P_r$ and generator input distribution coming from $ \\mathbb  P_z$, the original GAN objective function is defined as:\n",
    "\n",
    "$$\\mathcal{L} =\\min_w \\max_\\phi \\mathcal{l} \\ (w, \\phi) = \\min_w \\max_\\phi \\mathop{\\mathbb{E}_{z \\sim \\mathbb  P_z}} [ \\log (1 - f(g(z;w); \\phi))] + \\mathop{\\mathbb{E}_{x \\sim \\mathbb  P_r}} [\\log f(x; \\phi)] \\ \\ \\ \\ \\ \\text{(1)} $$ \n",
    "\n",
    "where w and $\\phi$ are the weights of the generator and the discriminator respectively.\n",
    "\n",
    "However, empirically, if the generator's loss is converted to $-E_{z \\sim p_z}[\\log f(g(z;w), \\phi)]$, then the gradient vanishing problem becomes less severe and training performance improves. The idea is to continue to use cross entropy minimization, but to get better gradients. **In this part, you need to use this modified loss to train GAN model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Implement Your GAN\n",
    "In this question, you will train a GAN to generate new face images by using celebrity dataset ([CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)) as the training set. You can find the data on scc:/projectnb/dl-course/HW4/celebA. We skipped the last 9 images in order to use as test images in Q3, but feel free to choose different face images!  \n",
    "\n",
    "You need to write codes step by step as desired. \n",
    "- This time PIL image library is used to preprocess input data.\n",
    "- The parameters are stored in an Arguments class instance. \n",
    "- Dataset class contains necessary functions for preprocessing and visualizing images.\n",
    "- Generator and Discriminator models are defined as a function. \n",
    "\n",
    "Tricks that are used to improve training of the model:\n",
    "- Deconvolutional layers\n",
    "- Leaky RELU\n",
    "- Using strided convolutions instead of pooling.\n",
    "- Using batch normalization\n",
    "- Not including fully connected layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Arguments(object):\n",
    "    data_path = 'path/to/celebA'\n",
    "    image_size = 64\n",
    "    num_images = 202590\n",
    "    batch_size = 64   \n",
    "    dim_z = 100           \n",
    "    n_gfilters = 64             \n",
    "    n_ffilters = 64              \n",
    "    n_epoch = 25            \n",
    "    lr = 0.002           \n",
    "    beta1 = 0.5   \n",
    "    beta2 = 0.99\n",
    "\n",
    "\n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object): \n",
    "    \n",
    "    def __init__(self, data_path, target_imgsize, num_imgs): \n",
    "        self.data_path = data_path\n",
    "        self.num_imgs = num_imgs\n",
    "        self.target_imgsize = target_imgsize \n",
    "        self.data_namelist = self.get_imagelist(self.data_path)\n",
    "\n",
    "\n",
    "    def get_imagelist(self, data_path): \n",
    "        imgs_path = os.path.join(data_path, 'img_align_celeba/*.jpg')\n",
    "        all_namelist = glob.glob(imgs_path, recursive=True)\n",
    "        data_namelist = all_namelist[:self.num_imgs] \n",
    "        return data_namelist \n",
    "\n",
    "    def load_and_process_image(self, image_path):\n",
    "        image = Image.open(image_path)\n",
    "        j = (image.size[0] - 100) // 2\n",
    "        i = (image.size[1] - 100) // 2\n",
    "        image = image.crop([j, i, j + 100, i + 100])    \n",
    "        image = image.resize([self.target_imgsize, self.target_imgsize], Image.BILINEAR)\n",
    "        image = np.array(image.convert('RGB')).astype(np.float32)\n",
    "        image = (image / np.amax(image) - 0.5) / 0.5\n",
    "        return image\n",
    "    \n",
    "    def get_nextbatch(self, batch_size): \n",
    "        cur_idx = 0\n",
    "        assert (batch_size > 0),\"Give a valid batch size\"\n",
    "        while cur_idx + batch_size <= self.num_imgs:\n",
    "            cur_namelist = self.data_namelist[cur_idx:cur_idx + batch_size]\n",
    "            cur_batch = [self.load_and_process_image(image_path) for image_path in cur_namelist]\n",
    "            cur_batch = np.array(cur_batch).astype(np.float32)\n",
    "            cur_idx += batch_size\n",
    "            yield cur_batch\n",
    "      \n",
    "    def show_image(self, image, normalized=True): \n",
    "        if not type(image).__module__ == np.__name__:\n",
    "            image = image.numpy()\n",
    "        npimg = (image * 0.5) + 0.5\n",
    "        npimg.astype(np.uint8)\n",
    "        plt.imshow(npimg, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(x, args, reuse=False):\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"generator\", reuse=reuse): \n",
    "            #Layer Block 1\n",
    "            with tf.variable_scope(\"layer1\"):\n",
    "                deconv1 = tf.layers.conv2d_transpose(inputs=x, \n",
    "                                             filters=64*8, \n",
    "                                             kernel_size=4, \n",
    "                                             strides=1,\n",
    "                                             padding='valid',\n",
    "                                             use_bias=False,\n",
    "                                             name='deconv')\n",
    "                batch_norm1=tf.layers.batch_normalization(deconv1,\n",
    "                                             name = 'batch_norm')\n",
    "                relu1 = tf.nn.relu(batch_norm1, name='relu')\n",
    "            #Layer Block 2\n",
    "            with tf.variable_scope(\"layer2\"):\n",
    "                deconv2 = tf.layers.conv2d_transpose(inputs=relu1, \n",
    "                                             filters=64*4, \n",
    "                                             kernel_size=4,\n",
    "                                             strides=2,\n",
    "                                             padding='same', \n",
    "                                             use_bias=False,\n",
    "                                             name='deconv')\n",
    "                batch_norm2 = tf.layers.batch_normalization(deconv2,\n",
    "                                             name = 'batch_norm')\n",
    "                relu2 = tf.nn.relu(batch_norm2, name='relu')\n",
    "            #Layer Block 3\n",
    "            with tf.variable_scope(\"layer3\"):\n",
    "                deconv3 = tf.layers.conv2d_transpose(inputs=relu2, \n",
    "                                             filters=64*2, \n",
    "                                             kernel_size=4, \n",
    "                                             strides=2, \n",
    "                                             padding='same',\n",
    "                                             use_bias = False,\n",
    "                                             name='deconv')\n",
    "                batch_norm3 = tf.layers.batch_normalization(deconv3, \n",
    "                                             name = 'batch_norm')\n",
    "                relu3 = tf.nn.relu(batch_norm3, name='relu')\n",
    "            #Layer Block 4\n",
    "            with tf.variable_scope(\"layer4\"):\n",
    "                deconv4 = tf.layers.conv2d_transpose(inputs=relu3, \n",
    "                                             filters=64, \n",
    "                                             kernel_size=4, \n",
    "                                             strides=2,\n",
    "                                             padding='same',\n",
    "                                             use_bias=False,\n",
    "                                             name='deconv')\n",
    "                batch_norm4 = tf.layers.batch_normalization(deconv4,\n",
    "                                             name = 'batch_norm')\n",
    "                relu4 = tf.nn.relu(batch_norm4, name='relu')\n",
    "            #Output Layer\n",
    "            with tf.variable_scope(\"last_layer\"):\n",
    "                logit = tf.layers.conv2d_transpose(inputs=relu4, \n",
    "                                             filters=3, \n",
    "                                             kernel_size=4, \n",
    "                                             strides=2, \n",
    "                                             padding='same',\n",
    "                                             use_bias=False,\n",
    "                                             name='logit')\n",
    "                output = tf.nn.tanh(logit) \n",
    "    return output, logit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x, args, reuse=False):\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope(\"discriminator\", reuse=reuse): \n",
    "            with tf.variable_scope(\"layer1\"):\n",
    "                conv1 = tf.layers.conv2d(inputs=x,\n",
    "                                         filters=64,\n",
    "                                         kernel_size=4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         name='conv')\n",
    "                relu1 = tf.nn.leaky_relu(conv1, alpha=0.2, name='relu')\n",
    "            with tf.variable_scope(\"layer2\"):\n",
    "                conv2 = tf.layers.conv2d(inputs=relu1,\n",
    "                                         filters=64*2,\n",
    "                                         kernel_size=4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         name='conv')\n",
    "                batch_norm2 = tf.layers.batch_normalization(conv2,name='batch_norm')\n",
    "                relu2 = tf.nn.leaky_relu(batch_norm2, alpha=0.2, name='relu')\n",
    "            with tf.variable_scope(\"layer3\"):\n",
    "                conv3 = tf.layers.conv2d(inputs=relu2,\n",
    "                                         filters=64*4,\n",
    "                                         kernel_size=4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         name='conv')\n",
    "                batch_norm3 = tf.layers.batch_normalization(conv3, name='batch_norm')\n",
    "                relu3 = tf.nn.leaky_relu(batch_norm3, name='relu')\n",
    "            with tf.variable_scope(\"layer4\"):\n",
    "                conv4 = tf.layers.conv2d(inputs=relu3,\n",
    "                                         filters=64*8,\n",
    "                                         kernel_size=4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         use_bias=False,\n",
    "                                         name='conv')\n",
    "                batch_norm4 = tf.layers.batch_normalization(conv4, name='batch_norm')\n",
    "                relu4 = tf.nn.leaky_relu(batch_norm4, alpha=0.2, name='relu')\n",
    "            with tf.variable_scope(\"last_layer\"):\n",
    "                logit = tf.layers.conv2d(inputs=relu4,\n",
    "                                         filters=1,\n",
    "                                         kernel_size=4,\n",
    "                                         strides=1,\n",
    "                                         padding='valid',\n",
    "                                         use_bias=False,\n",
    "                                         name='conv')\n",
    "                output = tf.nn.sigmoid(logit) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1\n",
    "Write a function that samples from a normal distribution with mean 0 and variance 1. The output vector should have dimensions (number of batch, 1, 1, dimension of the generator input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_z(z_dim, num_batch):\n",
    "    pass\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2\n",
    "Write a function that takes discriminator outputs of real data and fake data and returns generator and discriminator losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_losses(): #put inputs yourself \n",
    "    pass\n",
    "    return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.3\n",
    "Write a function that takes optimization parameters as input and returns optimizer functions for discriminator and generator in tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimizers(lr, beta1, beta2):\n",
    "    pass\n",
    "    return d_optimizer, g_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.4\n",
    "Write a function that takes optimizers and losses of G and D, minimizes each loss and updates network parameters. Make sure to avoid training of G's parameters while D is being optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(d_optimizer, g_optimizer, d_loss, g_loss):\n",
    "    pass\n",
    "    return d_step, g_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.5\n",
    "Now, you will combine the functions you defined and perform a complete GAN training. Save generator's and dicriminator's loss function plots and test generator output images(You can write a helper function to put images in grid and display multiple images on the same plot). Save the weights of your model since they will be used in the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    #fill\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(num_epoch):\n",
    "            for itr, real_batch in enumerate(get_nextbatch(batch_size)):\n",
    "                #fill\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.6\n",
    "Train the model for 5 different learning rates, and embed loss functions on one plot for the generator losses and one plot for the discriminator losses. You can smooth graphs to make the plots more interpretable. Compare output images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.7 (Bonus)\n",
    "Search for different loss functions to improve GAN performance other than the ones used here, and apply one of them that ideally improves the training. You may need to makes changes in discriminator or generator model, if you do, redefine them here with different names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_losses(d_real_out, d_fake_out): \n",
    "    pass\n",
    "    return d_loss, g_loss\n",
    "\n",
    "def new_train(args):\n",
    "    #fill\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(num_epoch):\n",
    "            for itr, real_batch in enumerate(get_nextbatch(batch_size)):\n",
    "                #fill\n",
    "                pass            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Image Filling by using GAN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you will implement an image filling application by using the GAN model you trained in the previous part. The main idea is that if a GAN model is trained well enough, then it should have a good representation of real data. For example, an image that is not from real data should not have a latent encoding on the z domain. Therefore, we want to find an encoding z that will be decoded by generator to be the closest to the occluded image. An example occluded input image is:  \n",
    "\n",
    "<img src=\"image.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "We will search over z domain of the GAN model we trained in part 2. Write the codes step by step, as explained below: (observe that we will not be retraining GAN model!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "args.z_iter = 1500\n",
    "args.alpha = 3e-3 \n",
    "args.epsilon = 1e-12 \n",
    "args.batch_size = 128\n",
    "args.mask_height = 32\n",
    "args.mask_width = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1\n",
    "First, create an image that looks normal, but has a 'superimposed' black square region. Basically you will take an image from CelebA dataset and remove a square region. \n",
    "\n",
    "Write a function that creates a mask which has the same size with the original input image; that has value 1 on a small square, and has value 0 on the other regions. Don't forget that we work on RGB scale!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_mask(mask_height, mask_width, image_height, image_width):\n",
    "    pass\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2\n",
    "\n",
    "Now get a sample image from CelebA dataset. Write a function that applies a mask to the image in a such way that output image should have value 1 on the missing patch and original pixel values on the other regions. Visualize the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_mask(mask, input_image):\n",
    "    pass\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3\n",
    "\n",
    "We already got the idea that we want to search over the z domain to get a close complete image. How do we define closeness between images? We will combine two different losses for our task. \n",
    "\n",
    "- The first one is to ensure that we get realistic images. We will use discriminator GAN loss for that purpose. It favors z values that produces images that are classified as real by discriminator(closer to 1). $\\alpha$ is a weighting term to balance between two losses and epsilon is for regularization:\n",
    "\n",
    "$$ \\mathcal L_{disc} = \\alpha \\log (1 - f(g(z)) + \\epsilon)$$\n",
    "\n",
    "- The second one is related to the context of the image. We do not want already existing pixels in the image to change much. So we use L2 loss to capture existing information. \n",
    "$$  \\mathcal L_{context} = {\\parallel (1 - M) \\odot (y - g(z)) \\parallel}_1 $$\n",
    "where y is the occluded image, M is the mask defined above and z is the current input to the generator.\n",
    "\n",
    "This time figure out the necessary inputs to the get_loss function by yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loss(): #put inputs yourself\n",
    "    pass\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.4\n",
    "\n",
    "Now, write the main function by using the functions you wrote above. After each iteration, we clip z values between -1 and 1 to ensure that we are in the feasible latent space.\n",
    "When the training is complete, you get a good z for the task, so giving it to the generator as an input will output an image. Fill the missing part of the input image with the output image by taking the corresponding patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_filling(image, mask, args):\n",
    "    #fill\n",
    "    for itr in range(): \n",
    "        with tf.Session() as sess:\n",
    "            #fill\n",
    "            if itr % 10 == 0:\n",
    "                #test\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Deep Understanding the GAN Loss (Bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that the generator is defined by a function $g(z ; w)$ where z is sampled from a random distribution $\\mathbb P_z (z)$, and the discriminator is defined by $f(y ;\\phi)$ _that tries to output high probability value if y is a real sample coming from the distribution $\\mathbb P_r(x)$, and a low probability value if y is a fake sample, i.e. when $y= g(z; w)$_; whereas $w$ and $\\phi$ are the weights of the generator and coming from the discriminator respectively. We ignore the dependence of weights to the data in notation.\n",
    "Then the original objective function is defined as:\n",
    "\n",
    "$$\\mathcal{L}(\\mathbb P_z, \\mathbb P_r) =\\min_w \\max_\\phi \\mathcal{l} \\ (\\mathbb P_z, \\mathbb P_r, w, \\phi) = \\min_w \\max_\\phi \\mathop{\\mathbb{E}_{z \\sim \\mathbb  P_z}} [ \\log (1 - f(g(z;w); \\phi))] + \\mathop{\\mathbb{E}_{x \\sim \\mathbb  P_r}} [\\log f(x; \\phi)] \\ \\ \\ \\ \\ \\text{(1)} $$ \n",
    "\n",
    "We will continue with notations $\\mathcal{L}$ and $l(w, \\phi)$ by dropping $\\mathbb P_z$ and $\\mathbb P_r$ from the notations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1.1\n",
    "Define the distribution of the generator output as $\\mathbb P_y$. Show that $\\mathop{\\mathbb{E}_{z \\sim \\mathbb  P_z}} [ \\log (1 - f(g(z;w); \\phi))] = \\mathop{\\mathbb{E}_{y \\sim \\mathbb  P_y}} [ \\log (1 - f(y; \\phi))]$. Is g invertible? How does this affect the method you use? Here is a useful link: [Change of variables](https://www.le.ac.uk/users/dsgp1/COURSES/LEISTATS/STATSLIDE4.pdf?fbclid=IwAR0XH32hlr58mJe80CPLS0_MdQ6dHtPaMsWFfEZDII37M5U4Mr0-6Zf6o_g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1.2\n",
    "\n",
    "Rewrite this loss as a combination of (expected) binary cross entropy loss functions; in terms of $f$, $g$, $\\mathbb P_r$ and $\\mathbb P_y$. Relate it with the above statement (written in italic ) with the discriminator's aim, and conclude that the discriminator is acting as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2\n",
    "\n",
    "Rewrite this loss as a combination of (expected) binary cross entropy loss functions; in terms of $f$, $g$, $\\mathbb P_r$ and $\\mathbb P_y$. Relate it with the above statement (written in italic ) with the discriminator's aim, and conclude that the discriminator is acting as a classifier.\n",
    "Now let us interpret this objective function from another but related perspective. This time, we will show that an **optimal** discriminator measures [Jensen-Shannon](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence) divergence between real and fake distributions. Do the following steps:\n",
    "\n",
    "### Q3.2.1\n",
    "\n",
    "Write the **optimal** discriminator function $f^*$ in terms of $\\mathbb  P_r$ and $\\mathbb  P_y$ (hint: take proper derivatives to reach the solution. You may want to define the discriminator output as a new variable).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2.2\n",
    "\n",
    "Now put $f^*$ found in 1.2.1 into the equation and find $ \\max_\\phi$. Use the equality below to conclude  \n",
    "\n",
    "$$ \\max_\\phi l(w, \\phi) := \\mathcal{l}(w, \\phi_{f^*}) = 2 * JS(\\mathbb  P_r \\parallel \\mathbb  P_y ) - log(4) $$\n",
    "\n",
    "Briefly mention the difference between JS and KL divergences.\n",
    "\n",
    "(Note: add and substract $\\log 4$ to get to the solution. First try to write in terms of [KL divergences](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence), then use the relation below to achieve JS divergence) \n",
    "\n",
    "\n",
    "$$JS(p, q) = \\frac{KL(p \\parallel \\frac{p+q}{2}) + KL(q \\parallel \\frac{p+q}{2})}{2}$$\n",
    "\n",
    "\n",
    "$$KL(p,q) = \\int p \\log \\frac{p}{q} d\\mu$$ \n",
    "\n",
    "1.2.3 Now the generator's loss function becomes: $\\min_w \\mathcal{l}(w, \\phi_{f^*})$. Since JS divergence has minimum 0 we reach the global optimum at the value $- \\log 4$. Show that this optimum is achieved when  $\\mathbb  P_r = \\mathbb  P_y$ and it is unique. Comment on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3\n",
    "\n",
    "Now consider the problem as an optimization problem with the gradient descent method. In reality, with this loss function, instead of training the discriminator first and getting $f^*$, the training is done alternatingly. We will create a simple scenario where we start with an optimal f, and training g would not work. \n",
    "\n",
    "### Q3.3.1\n",
    "\n",
    "Assume real data is of the form $(0, x)$ and the generator input is of the form $(1, x)$, and $x \\sim Unif(0,5)$ The generator is defined by a single parameter $w$, which adds $(w, 0)$ to the input. Observe that the generator has enough capacity to capture real data.  \n",
    "\n",
    "Write an experiment that starts from any  $w \\neq w_{optimal}$. Try to apply gradient descent on the generator with the optimal discriminator. Conclude that an optimal solution cannot be found.(Consider the gradients of the loss and $w$ update of the generator. Also remember that an optimal discriminator measure JS divergence!)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3.2\n",
    "In addition, we do not have a real data distribution in a real case, so the loss function turns out to be a finite sum. What might go wrong because of this approximation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: RNN \n",
    "\n",
    "## Q4. RNN Example\n",
    "\n",
    "In this example we train an RNN to infer the parameters of a simple dynamical system.\n",
    "First, we simulate a dynamical system with known parameters (random numbers), and use it to generate outputs. Then, we train an RNN on the generated datapoints, attempting to infer the original parameters.\n",
    "You are expected to run and study the provided code, which will be helpful for the second part (implementing LSTM).\n",
    "\n",
    "1. We define a discretized [dynamical system](https://en.wikipedia.org/wiki/Dynamical_system).\n",
    "At each discrete time $t$, the system observes input $x_t$. The system maintains some \"state\" $h_t$, which will be updated over time.\n",
    "Specifically, the states are updated by the following rule: $h_t = \\max(0, 1-(Wx_t+h_{t-1}))$, where $W$ is a parameter matrix.\n",
    "2. In this example, the input data $\\{x_t\\}$ is randomly generated, and the weight matrix $W$ is also drawn randomly. The system starts from an initial hidden state $h_0$, and runs for $t=1,\\ldots,T$.\n",
    "3. Given the sequence of states $\\{h_1,\\ldots,h_T\\}$, we would like to infer the weights $W$.\n",
    "\n",
    "To start with, the following code segment generates and displays the data.\n",
    "Refer to `data_generator.py` for details of data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we present sample data generated \n",
    "import numpy as np\n",
    "import data_generator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(h_0, w), x, h = data_generator._build_rnn_testdata_matrix()\n",
    "\n",
    "print('variable name, shape, min, max: ')\n",
    "for v, name in zip([h_0, w, x], ['h0', 'w', 'x']):\n",
    "    print(name, v.shape, np.min(v), np.max(v))\n",
    "norm_x_t = np.sum(x**2, axis=1)\n",
    "plt.title('||x(t)||')\n",
    "plt.plot(np.arange(norm_x_t.shape[0]), norm_x_t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We model the dynamical system with an RNN. We would like the state generated by the RNN to match the actual observed, and we use L2 loss for this purpose.\n",
    "This RNN is a *regression* model since it outputs real values.\n",
    "\n",
    "Below, `build_rnn_regression_model()` gives the model definition, and `train_rnn_with_noise()` generates a batch of data and then runs training on it. \n",
    "We corrupt the data generation process with noise, and let the dimensionality of the state $h$ be a free parameter. Therefore, the training function takes two input arguments: `noise_level` and `n_hidden_dim`.   You will later see how varying them affects reconstruction quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "\n",
    "#############################################################################\n",
    "# RNN model graph\n",
    "def build_rnn_regression_model(shape):\n",
    "    # shape is dict with keys:\n",
    "    # n_steps_per_batch, n_hidden_dim, n_input_dim\n",
    "    with tf.Graph().as_default() as g:\n",
    "        # inputs to the dynamical system\n",
    "        X = tf.placeholder(tf.float32,\n",
    "                           [None, shape['n_steps_per_batch'], shape['n_input_dim']])\n",
    "        # observed state from the dynamical system\n",
    "        y = tf.placeholder(tf.float32, [None, shape['n_hidden_dim']])\n",
    "        \n",
    "        with tf.variable_scope('weights'):\n",
    "            # weight matrix\n",
    "            w = tf.get_variable('w', [shape['n_input_dim'], shape['n_hidden_dim']])\n",
    "            # initial state\n",
    "            h_0 = tf.get_variable('h_0', [shape['n_hidden_dim']])\n",
    "            \n",
    "        # for t = 1 to T, update state \n",
    "        h_t = h_0\n",
    "        for t in range(shape['n_steps_per_batch']):\n",
    "            x_t = X[:, t, :]\n",
    "            h_t = tf.maximum(0.0, 1 - (tf.matmul(x_t, w) + h_t))\n",
    "        \n",
    "        # loss: L2\n",
    "        loss = tf.nn.l2_loss(h_t - y, name='loss')\n",
    "        train_op = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
    "        summ = tf.summary.scalar('loss_sum_%dd' % shape['n_hidden_dim'], loss)\n",
    "        \n",
    "    return {'inputs': [X, y], 'loss': loss, 'train_op': train_op, 'summ': summ,\n",
    "            'weights': {'w': w, 'h_0': h_0}, 'graph': g}\n",
    "\n",
    "#############################################################################\n",
    "# Main train loop for an RNN regression model\n",
    "# \n",
    "# This takes synthetic data generated by data_generator.build_dataset()\n",
    "# the weight matrix W is then inferred with back-prop \n",
    "def train_rnn_with_noise(noise_level, n_hidden_dim):\n",
    "    # generate data\n",
    "    shapes = dict(n_hidden_dim=n_hidden_dim, n_input_dim=15, n_steps_per_batch=100)\n",
    "    rnn_dataset = data_generator.build_dataset('rnn', noise=noise_level, **shapes)\n",
    "    (h0_true, w_true), batched_data = rnn_dataset  # \"true\" weights\n",
    "    # build RNN model\n",
    "    model = build_rnn_regression_model(shapes)\n",
    "    \n",
    "    #logdir = './tensorboard/rnn_demo'  # if on Windows\n",
    "    logdir = '/tmp/tensorboard/rnn_demo'  # if on Unix\n",
    "    try:\n",
    "        os.makedirs(logdir)\n",
    "    except os.error:\n",
    "        pass\n",
    "    # If you want to see the plots, run tensorboard:\n",
    "    # $ tensorboard --logdir=[your_logdir]\n",
    "    #\n",
    "    # If you use SCC, you can forward the 6006 port from the cluster \n",
    "    # to your local machine via:\n",
    "    # $ ssh [SCC_cluster_name] -L 6006:localhost:6006\n",
    "    time_now = datetime.datetime.now().strftime(\"%d-%b-%H-%M-%S\")\n",
    "    run_name = 'hidden=%d_noise=%.2f' % (n_hidden_dim, noise_level)\n",
    "    sum_path = os.path.join(logdir, run_name + '_' + time_now)\n",
    "    print(sum_path)\n",
    "    max_iter_i = 0\n",
    "    with model['graph'].as_default() as g, tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sum_writer = tf.summary.FileWriter(sum_path, g)\n",
    "        for epoch_i in range(50):\n",
    "            loss_val, w_dist, h0_dist, iter_i = None, None, None, None\n",
    "            for iter_i, data_batch in enumerate(batched_data):\n",
    "                max_iter_i = max(iter_i, max_iter_i)\n",
    "                global_step = epoch_i*max_iter_i+iter_i\n",
    "                \n",
    "                # run training step\n",
    "                train_feed_dict = dict(zip(model['inputs'], data_batch))\n",
    "                to_compute = [model['train_op'], model['summ'], model['loss'],\n",
    "                              model['weights']['w'], model['weights']['h_0']]\n",
    "                _, summ, loss_val, w_val, h0_val = sess.run(to_compute, train_feed_dict)\n",
    "                \n",
    "                # compute reconstruction error\n",
    "                w_err = np.linalg.norm(w_true-w_val)\n",
    "                h0_err = np.linalg.norm(h0_true-h0_val)\n",
    "                \n",
    "                # for tensorboard\n",
    "                sum_writer.add_summary(summ, global_step)\n",
    "                sum_writer.add_summary(tf.Summary(value=[\n",
    "                    tf.Summary.Value(tag=\"w_true_dist_%dd\" % n_hidden_dim,\n",
    "                                     simple_value=w_err),\n",
    "                ]), global_step)\n",
    "                sum_writer.add_summary(tf.Summary(value=[\n",
    "                    tf.Summary.Value(tag=\"h_true_dist_%dd\" % n_hidden_dim,\n",
    "                                     simple_value=h0_err),\n",
    "                ]), global_step)\n",
    "                sum_writer.flush()\n",
    "                \n",
    "            print('epoch %d, loss=%g, w_err=%g'%(epoch_i, loss_val, w_err))\n",
    "            if global_step > 200: \n",
    "                break  # just train for 200 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the RNN wth varying noise levels and hidden dimensionalities.\n",
    "- For each combination of `n_hidden_dim` and `noise_level`, report the reconstruction error (`w_err`).\n",
    "- Describe how the hidden dimentionality and the noise level influence reconstruction quality. And briefly explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Experimenting with different data noise levels and hidden dimentionalities\n",
    "# We are lucky to know the true hidden dimentionality in our simultaion\n",
    "for n_hidden_dim in [10, 100, 1000]:\n",
    "    for noise_level in [0, 0.1, 0.5]:\n",
    "        print(n_hidden_dim, noise_level)\n",
    "        train_rnn_with_noise(noise_level, n_hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: LSTM implementation\n",
    "\n",
    "Now let's attempt to recover the weights in dynamical system simulated with an LSTM.  Although LSTMs are already implemented in TensorFlow ([tutorial here](https://www.tensorflow.org/tutorials/recurrent)) ([source here](https://github.com/tensorflow/tensorflow/blob/efe5376f3dec8fcc2bf3299a4ff4df6ad3591c88/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L264)), you will be implementing a simple LSTM from scratch using Tensorflow in this part. \n",
    "\n",
    "\n",
    "### Q5.1 Implement an LSTM \n",
    "Implement an LSTM model in an analogous way,  in functions `build_lstm_regression_model()` and `train_lstm_with_noise()` below.\n",
    "The RNN regression implementation above should give you some ideas.\n",
    "We already provided an LSTM version of the dynamical system generator in the dataset generator code.\n",
    "\n",
    "- Specifically, you can follow and implement Eq. 1-6 from [this link](http://deeplearning.net/tutorial/lstm.html) in `build_lstm_regression_model()`. \n",
    "You may simplify your code by concatenating $x$ and $h$.\n",
    "- Afterwards, implement `train_lstm_with_noise()` to train the LSTM and recover the parameters. Compute the reconstruction errors for $W_c$ and $U_c$, which are the parameters used in Eq. 2 in the link.\n",
    "- For each combination of hidden dimension and noise level, report the reconstruction error (`w_err`, `u_err`) you get from the LSTM.\n",
    "\n",
    "Note:\n",
    "- The weights might not get reconstructed correctly in the LSTM case even without noise. (Why?)\n",
    "Nevertheless, the loss should decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_regression_model(shape):\n",
    "    # shape is dict with keys:\n",
    "    # n_steps_per_batch, n_hidden_dim, n_input_dim\n",
    "    with tf.Graph().as_default() as g:\n",
    "        # inputs\n",
    "        X = tf.placeholder(tf.float32,\n",
    "                           [None, shape['n_steps_per_batch'], shape['n_input_dim']])\n",
    "        # observed outputs\n",
    "        y = tf.placeholder(tf.float32, [None, shape['n_hidden_dim']])\n",
    "        \n",
    "        #################################################################\n",
    "        ####################  PUT YOUR CODE HERE   ######################\n",
    "        # define the parameters in the LSTM (scope: weights)\n",
    "        # and carry out the computation according to Eq. 1-6 in the link\n",
    "        with tf.variable_scope('weights'):\n",
    "            pass\n",
    "        output = None  # put your result in variable 'output'\n",
    "        #################################################################\n",
    "        \n",
    "        # loss and train_op\n",
    "        loss = tf.nn.l2_loss(output - y, name='loss')\n",
    "        train_op = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
    "        summ = tf.summary.scalar('loss_sum_%dd' % shape['n_hidden_dim'], loss)\n",
    "\n",
    "    return {'inputs': [X, y], 'loss': loss, 'train_op': train_op, 'summ': summ,\n",
    "            'weights': {'w_c': w_c, 'u_c': u_c}, \n",
    "            'graph': g}\n",
    "    \n",
    "    \n",
    "def train_lstm_with_noise(noise_level, n_hidden_dim):\n",
    "    # generate data and random weights\n",
    "    shapes = dict(n_hidden_dim=n_hidden_dim, n_input_dim=15, n_steps_per_batch=100)\n",
    "    weights, batched_data = data_generator.build_dataset('lstm', noise=noise_level, **shapes)\n",
    "    w_c, u_c = weights[3], weights[7]  # the \"true\" weights to recover: Wc & Uc (in Eq.2)\n",
    "    \n",
    "    # this is the function you implemented\n",
    "    model = build_lstm_regression_model(shapes)\n",
    "    \n",
    "    #logdir = './tensorboard/lstm_demo'  # if on Windows\n",
    "    logdir = '/tmp/tensorboard/lstm_demo'  # if on Unix\n",
    "    try:\n",
    "        os.makedirs(logdir)\n",
    "    except os.error:\n",
    "        pass\n",
    "    time_now = datetime.datetime.now().strftime(\"%d-%b-%H-%M-%S\")\n",
    "    run_name = 'hidden=%d_noise=%.2f' % (n_hidden_dim, noise_level)\n",
    "    sum_path = os.path.join(logdir, run_name + '_' + time_now)\n",
    "    print(sum_path)\n",
    "    \n",
    "    max_iter_i = 0\n",
    "    with model['graph'].as_default() as g, tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sum_writer = tf.summary.FileWriter(sum_path, g)\n",
    "        for epoch_i in range(10):  # 10 epochs by default, feel free to change\n",
    "            loss_val, w_err, u_err, iter_i = None, None, None, None\n",
    "            for iter_i, data_batch in enumerate(batched_data):\n",
    "                max_iter_i = max(iter_i, max_iter_i)\n",
    "                global_step = epoch_i*max_iter_i+iter_i\n",
    "                \n",
    "                ###############################################################\n",
    "                ###################   PUT YOUR CODE HERE   ####################\n",
    "                train_feed_dict = None  # define your train_feed_dict\n",
    "                to_compute = []  # the things to compute, including at least:\n",
    "                                 # loss_val, w_err, u_err\n",
    "                outputs = sess.run(to_compute, train_feed_dict)\n",
    "                w_err = None  # compute them and report\n",
    "                u_err = None\n",
    "                # [optional] you can also do early stopping, e.g. 300 iterations\n",
    "                # if global_step > 300:\n",
    "                #    break\n",
    "                # use sum_writer for tensorboard, see train_rnn_with_noise()\n",
    "                sum_writer.add_summary(...)\n",
    "                sum_writer.flush()\n",
    "                ###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n_hidden_dim in [10, 100, 1000]:\n",
    "    for noise_level in [0, 0.1, 0.5]:\n",
    "        print(n_hidden_dim, noise_level)\n",
    "        train_lstm_with_noise(noise_level, n_hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6: Compose Music using a LSTM \n",
    "\n",
    "In this part you will train a music prediction LSTM that predicts the next note given previous notes.  \n",
    "\n",
    "### MIDI Data\n",
    "\n",
    "A file with the .MID or .MIDI file extension is a Musical Instrument Digital Interface file. Unlike regular audio files like MP3 or WAV files, MIDI files don't contain actual audio data and are therefore much smaller in size. For example, MID files explain what notes are played and how long or loud each note should be. Instead, they are basically instructional files that explain how the sound should be produced once attached to a playback device or loaded into a particular software program that knows how to interpret the data. This makes MIDI files perfect for sharing musical information between similar applications. Learn how to play a midi file: https://www.lifewire.com/midi-file-2621979.\n",
    "\n",
    "In this problem, we will use a small Mozart MIDI Corpus dataset [Mozarella](https://github.com/thakkarV/Mozarella) to train a LSTM for composing music. For each midi file, we extract an embedding matix with size of [num_note,87] - it has num_note continous notes and each note is represented by a 87-dim one-hot vector. Besides of embedding matix, we also prepare a matrix of duration with size of [num_note, 1] to save the duration time for each note. In this problem, we assume each note has same duration. The embedding and duration matrix are save on scc:  /projectnb/dl-course/HW4/Mozarella/midi_embedding.\n",
    "\n",
    "We have installed mozarella and midi on scc for you. If you want to play on a local machine, please follow the instruction of installation on [Mozarella](https://github.com/thakkarV/Mozarella).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Q6.1 LSTM with Discrete Outputs\n",
    "Compared to the LSTM you implemented in the previous part, the main difference in the music prediction LSTM is that it predicts *discrete* outputs, therefore it is a classification model. As you may recall, the usual choice of loss function for classification is softmax + cross entropy.\n",
    "\n",
    "We have already provided functions for loading the training data. Please define your discrete LSTM in `build_lstm_discrete_prediction_model()`.\n",
    "\n",
    "Hints: \n",
    "- Your LSTM should predict a single note at a time. We are not considering  many-to-many LSTMs here.\n",
    "- Feeding the previous input into the LSTM should help.\n",
    "\n",
    "Feel free to change the paramenters or codes if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import midi_reader\n",
    "emb_pkl_path = '/projectnb/dl-course/HW4/Mozarella/midi_embedding/'\n",
    "\n",
    "\n",
    "def get_default_gpu_session(fraction=0.333):\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = fraction\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "def run_midi_train(n_hid):\n",
    "    # generate data\n",
    "    btg = midi_reader.batch_midi_generator_from_pkl(emb_pkl_path, batch_size=15, seq_size=360)\n",
    "    shape = dict(n_steps_per_batch=360, n_unique_ids=87, n_hidden_dim=n_hid)\n",
    "    # define LSTM\n",
    "    model = build_lstm_discrete_prediction_model(shape)\n",
    "    \n",
    "    #logdir = './tensorboard/midi'  # if on Windows\n",
    "    logdir = '/tmp/tensorboard/midi'  # if on Unix\n",
    "    try:\n",
    "        os.makedirs(logdir)\n",
    "    except os.error:\n",
    "        pass\n",
    "    time_now = datetime.datetime.now().strftime(\"%d-%b-%H-%M-%S\")\n",
    "    run_name = 'hidden=%d' % n_hid\n",
    "    sum_path = os.path.join(logdir, run_name + '_' + time_now)\n",
    "    print(sum_path)\n",
    "    max_iter_i = 0\n",
    "    with model['graph'].as_default() as g, get_default_gpu_session(0.9) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sum_writer = tf.summary.FileWriter(sum_path, g)\n",
    "        for epoch_i in range(10):\n",
    "            for iter_i, data_batch in enumerate(btg):\n",
    "                max_iter_i = max(iter_i, max_iter_i)\n",
    "                global_step = epoch_i*max_iter_i+iter_i\n",
    "                \n",
    "                # run training step\n",
    "                train_feed_dict = dict(zip(model['inputs'], data_batch))\n",
    "                to_compute = [model['train_op'], model['summ'], model['loss']]\n",
    "                _, summ, loss_val = sess.run(to_compute, train_feed_dict)\n",
    "                \n",
    "                # for tensorboard\n",
    "                sum_writer.add_summary(summ, global_step)\n",
    "                sum_writer.flush()\n",
    "                \n",
    "            print(loss_val, end=', ')\n",
    "\n",
    "            # test generation\n",
    "            pred_length = 50\n",
    "            data_input = next(iter(btg))[0][[0]]\n",
    "            original_sample = data_input.copy()\n",
    "            pred_seq = []\n",
    "            for _ in range(pred_length):\n",
    "                pred = sess.run(model['pred'], {model['inputs'][0]: data_input})\n",
    "                pred_seq.append(pred[0])\n",
    "                data_input = np.roll(data_input, -1, axis=1)\n",
    "                data_input[0, -1] = pred[0]\n",
    "\n",
    "            print(pred_seq)\n",
    "            print()\n",
    "            \n",
    "                \n",
    "def build_lstm_discrete_prediction_model(shape):\n",
    "    # shape is dict with keys:\n",
    "    # n_steps_per_batch, n_unique_ids, n_hidden_dim\n",
    "    with tf.Graph().as_default() as g:\n",
    "        X = tf.placeholder(tf.int64, [None, shape['n_steps_per_batch']])\n",
    "        y = tf.placeholder(tf.int64, [None])\n",
    "        \n",
    "        ################################################################\n",
    "        ####################   PUT YOUR CODE HERE   ####################\n",
    "        # define LSTM parameters (scope: weights)\n",
    "        with tf.variable_scope('weights'):\n",
    "            pass\n",
    "        logits = None  # compute logits for each discrete output\n",
    "        loss = None  # compute loss with respect to (logits, y)\n",
    "        ################################################################\n",
    "\n",
    "        # pred, train_op\n",
    "        pred = tf.argmax(logits, axis=1)\n",
    "        train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "        summ = tf.summary.scalar('loss_summ', loss)\n",
    "\n",
    "    return {'inputs': [X, y], 'loss': loss, 'train_op': train_op, 'summ': summ,\n",
    "            'graph': g, 'pred': pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = 50\n",
    "run_midi_train(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6.2 Let's Check Your Music!\n",
    "\n",
    "Now you have your prediction and the next step to convert it back into midi files using midi_reader.save_to_mid(pred_seq, 'path/to/save/out.mid')\n",
    "\n",
    "Please submit your result in .mid format. Report the performance and explain why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 Composing Better Music (Bonus)\n",
    "\n",
    "Try to improve your music prediction.\n",
    "\n",
    "Hint:\n",
    "\n",
    "You can try to improve your music in different ways. For example:\n",
    "\n",
    "1. Use a better RNN model such as bidirectional LSTM.\n",
    "2. Add the duration of each note into your model. \n",
    "\n",
    "The duration of each note is save in all_raw_duration.pkl at scc: /projectnb/dl-course/HW4/Mozarella/midi_embedding. Or you can extract the features from midi data using mozarella.midi_embedding_generator(). The output of midi_embedding_generator() is a [num_note,88] embedding where the first 87 elements are one-hot embedding and the last one is the corresponding duration. You can use mozarella.generate_midi_from_embeddings() to save your results. \n",
    "\n",
    "Please submit your result in .mid format. Report the performance and explain why.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
